{"cells":[{"cell_type":"markdown","metadata":{"id":"yRxmOFfSMzQB"},"source":["# LWCC\n","\n","https://github.com/tersekmatija/lwcc\n"]},{"cell_type":"markdown","source":["## Configuration"],"metadata":{"id":"lcxM9Eghovzd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zw3_PO2GMpIx"},"outputs":[],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GM67ermgMtgk"},"outputs":[],"source":["# Installation\n","!pip install lwcc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZHOm1JxMuTJ"},"outputs":[],"source":["# Python Imports\n","import cv2\n","import glob\n","import h5py\n","import json\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","import os\n","import pandas as pd\n","import scipy.io as io\n","import sklearn.metrics as skmetrics\n","import skimage.metrics as skimetrics\n","import time\n","\n","from pathlib import Path\n","from PIL import Image\n","from matplotlib import cm as c\n","from tqdm import tqdm\n","from scipy.ndimage import gaussian_filter\n","\n","from lwcc import LWCC\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4u0oyIRCZv4Y"},"outputs":[],"source":["# !pip install -Uqq ipdb\n","# import ipdb\n","# %pdb on"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjgRIHd0NzeU"},"outputs":[],"source":["# Constants\n","DEVICE = 'cpu'\n","\n","DRIVE_PATH = \"/content/drive/MyDrive\"\n","COLLAB_PATH = f\"{DRIVE_PATH}/Colab Notebooks CC\"\n","DATASETS_PATH = f\"{COLLAB_PATH}/Datasets\"\n","MODELS_PATH = f\"{COLLAB_PATH}/Models\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tpXB__EwMv5I"},"outputs":[],"source":["class Metrics(object):\n","  def __init__(self, eval_name, gt_count, pred_count, img_paths):\n","    self.eval_name = eval_name\n","    self.imgs = [os.path.basename(path) for path in img_paths]\n","    self.gt_count = np.array(gt_count); self.pred_count = np.array(pred_count)\n","    self.calculate_count_metrics()\n","    self.PSNR, self.SSIM, self.GAME4, self.GAME16 = [], [], [], []\n","    self.AVG_PSNR, self.AVG_SSIM, self.AVG_GAME4, self.AVG_GAME16 = None, None, None, None\n","    self.organize_by_img()\n","\n","  def __init__(self, eval_name, gt_count, gt_density, pred_count, pred_density, img_paths):\n","    self.eval_name = eval_name\n","    self.imgs = [os.path.basename(path) for path in img_paths]\n","    self.gt_count, self.pred_count = np.array(gt_count), np.array(pred_count)\n","    self.calculate_count_metrics()\n","    self.calculate_density_metrics(gt_density, pred_density)\n","    self.organize_by_img()\n","\n","  def calculate_count_metrics(self):\n","    self.MAE, self.MSE, self.RMSE = [], [], []\n","    for gt_count, pred_count in zip(self.gt_count, self.pred_count):\n","      self.MAE.append(skmetrics.mean_absolute_error([gt_count], [pred_count]))\n","      self.MSE.append(skmetrics.mean_squared_error([gt_count], [pred_count]))\n","      self.RMSE.append(skmetrics.mean_squared_error([gt_count], [pred_count], squared=False))\n","    self.AVG_MAE = np.mean(self.MAE)\n","    self.AVG_MSE = np.mean(self.MSE)\n","    self.AVG_RMSE = math.sqrt(np.mean(self.MSE))\n","\n","  def calculate_density_metrics(self, gt_density, pred_density):\n","    self.PSNR, self.SSIM, self.GAME4, self.GAME16 = [], [], [], []\n","    for gt_den, pred_den, pred_count in zip(gt_density, pred_density, self.pred_count):\n","      pred_den = cv2.resize(pred_den, dsize=(gt_den.shape[1], gt_den.shape[0]), interpolation=cv2.INTER_CUBIC)\n","      if np.sum(pred_den):\n","        pred_den = pred_count * pred_den / np.sum(pred_den)\n","      self.PSNR.append(skimetrics.peak_signal_noise_ratio(gt_den, pred_den))\n","      self.SSIM.append(skimetrics.structural_similarity(gt_den, pred_den))\n","      self.GAME4.append(self.calculate_game(gt_den, pred_den, blocks=4))\n","      self.GAME16.append(self.calculate_game(gt_den, pred_den, blocks=16))\n","    self.AVG_PSNR = np.mean(self.PSNR)\n","    self.AVG_SSIM = np.mean(self.SSIM)\n","    self.AVG_GAME4 = np.mean(self.GAME4)\n","    self.AVG_GAME16 = np.mean(self.GAME16)\n","\n","  def organize_by_img(self):\n","    metrics = [m for m in [self.MAE, self.MSE, self.RMSE, self.PSNR, self.SSIM] if m]\n","    self.metrics_by_img = {\n","        img_name: {\n","            \"MAE\": self.MAE[i],\n","            \"MSE\": self.MSE[i],\n","            \"RMSE\": self.RMSE[i],\n","            \"PSNR\": self.PSNR[i] if self.PSNR else None,\n","            \"SSIM\": self.SSIM[i] if self.SSIM else None,\n","            \"GAME4\": self.GAME4[i] if self.GAME4 else None,\n","            \"GAME16\": self.GAME16[i] if self.GAME16 else None\n","        } for i, img_name in enumerate(self.imgs)\n","    }\n","\n","  def display_metrics(self, img_name = None):\n","    if img_name:\n","      metrics = self.metrics_by_img[img_name]\n","      mae, mse, rmse, game4, game16, psnr, ssim = metrics[\"MAE\"], metrics[\"MSE\"], metrics[\"RMSE\"], metrics[\"GAME4\"], metrics[\"GAME16\"], metrics[\"PSNR\"], metrics[\"SSIM\"]\n","    else:\n","      mae, mse, rmse, game4, game16, psnr, ssim = self.AVG_MAE, self.AVG_MSE, self.AVG_RMSE, self.AVG_GAME4, self.AVG_GAME16, self.AVG_PSNR, self.AVG_SSIM\n","    print(f'{self.eval_name}, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f' % (mae, mse, rmse, game4, game16, psnr, ssim))\n","\n","  def calculate_game(self, gt_den, pred_den, blocks=4):\n","    result = 0  # Aggregation of errors per block (mean is calculated afterwards)\n","    gt_den_s = self.split_matrix(gt_den, blocks=blocks)\n","    pred_den_s = self.split_matrix(pred_den, blocks=blocks)\n","    for i, (gden, pden) in enumerate(zip(gt_den_s, pred_den_s), start=1):\n","      block_result = abs(np.sum(pden) - np.sum(gden))\n","      result += block_result\n","    return result\n","\n","  def split_matrix(self, matrix, blocks=4):\n","    if blocks == 4:\n","      T, B = np.array_split(matrix, 2)\n","      TL, TR = np.array_split(T, 2, axis=1)\n","      BL, BR = np.array_split(B, 2, axis=1)\n","      return [TL, TR, BL, BR]\n","    elif blocks == 16:\n","      T, MT, MB, B = np.array_split(matrix, 4)\n","      A11, A12, A13, A14 = np.array_split(T, 4, axis=1)\n","      A21, A22, A23, A24 = np.array_split(MT, 4, axis=1)\n","      A31, A32, A33, A34 = np.array_split(MB, 4, axis=1)\n","      A41, A42, A43, A44 = np.array_split(B, 4, axis=1)\n","      return [A11, A12, A13, A14, A21, A22, A23, A24, A31, A32, A33, A34, A41, A42, A43, A44]\n","\n","class Dataset(object):\n","  def __init__(self, name, root_path, img_format = \".jpg\"):\n","    self.name = name\n","    self.root = f\"{DATASETS_PATH}/{root_path}\"\n","    self.img_path = f\"{root_path}/images\"\n","    self.gt_path = f\"{root_path}/ground_truth\"\n","    self.img_format = img_format\n","    self.SIGMA = 15\n","\n","  def get_image_paths(self):\n","    return sorted(glob.glob(os.path.join(self.img_path, f'*{self.img_format}')))\n","\n","  def get_gt_for_img(self, img_path, return_density = True):\n","    raw_image = cv2.imread(img_path)\n","    gt_density = np.zeros(raw_image.shape[:2], dtype=np.float32).tolist()\n","    gt_count, gt_density = self.gt_to_binary_matrix(img_path, gt_density)\n","\n","    if return_density:\n","      gt_density = np.array(gt_density, dtype=np.float32)\n","      gt_density = gaussian_filter(gt_density, self.SIGMA, mode='constant')\n","      gt_density = gt_count * gt_density / np.sum(gt_density)\n","      return gt_count, gt_density\n","    return gt_count\n","\n","  def gt_to_binary_matrix(self, gt_path, gt_density):\n","    raise NotImplementedError\n","\n","class ShanghaiTech(Dataset):\n","  def __init__(self, id = \"A\"):\n","    super().__init__(name=f\"SH{id}\", root_path=f\"{DATASETS_PATH}/Shanghaitech/part_{id}_final/test_data\")\n","\n","  def gt_to_binary_matrix(self, img_path, gt_density):\n","    file_name = Path(img_path).stem\n","    gt_path = img_path.replace(file_name, f\"GT_{file_name}\").replace(self.img_format, \".mat\").replace('images', 'ground_truth')\n","\n","    mat = io.loadmat(gt_path)[\"image_info\"]\n","    gt_count = mat[0,0][0,0][1][0][0]\n","    gt_points = mat[0,0][0,0][0]\n","    for x, y in gt_points:\n","      x = max(0, min(int(x), len(gt_density[0])-1)); y = max(0, min(int(y), len(gt_density)-1))\n","      gt_density[y][x] = 1\n","    return gt_count, gt_density\n","\n","class UCF(Dataset):\n","  def __init__(self, id = \"CC50\"):\n","    if id == \"CC50\":\n","      super().__init__(name=\"UCF-CC50\", root_path=f\"{DATASETS_PATH}/UCF_CC\")\n","    elif id == \"QNRF\":\n","      super().__init__(name=\"UCF-QNRF\", root_path=f\"{DATASETS_PATH}/UCF-QNRF_ECCV18/Test\")\n","    else:\n","      raise ValueError\n","\n","  def gt_to_binary_matrix(self, img_path, gt_density):\n","    file_name = Path(img_path).stem\n","    gt_path = img_path.replace(file_name, f\"{file_name}_ann\").replace(self.img_format, \".mat\").replace('images', 'ground_truth')\n","\n","    mat = io.loadmat(gt_path)[\"annPoints\"]\n","    gt_count = len(mat)\n","    gt_points = mat\n","    for x, y in gt_points:\n","      x = max(0, min(int(x), len(gt_density[0])-1)); y = max(0, min(int(y), len(gt_density)-1))\n","      gt_density[y][x] = 1\n","    return gt_count, gt_density\n","\n","class NWPUCounting(Dataset):\n","  def __init__(self):\n","    super().__init__(name=\"NWPUC\", root_path=f\"{DATASETS_PATH}/UCF-NWPU_Crowd_min_576x768_mod16_2048/test_data\")\n","\n","class MT(Dataset):\n","  def __init__(self, id=\"A\"):\n","    super().__init__(name=f\"MT\", root_path=f\"{DATASETS_PATH}/MT\")\n","\n","  def gt_to_binary_matrix(self, img_path, gt_density):\n","    gt_path = img_path.replace(self.img_format, \".json\").replace('images', 'ground_truth')\n","    with open(gt_path, 'r') as json_data:\n","      gt_raw = json.loads(json_data.read())\n","    gt_count = gt_raw[\"human_num\"]\n","    for p in gt_raw[\"points\"]:\n","      x = max(0, min(int(p[\"x\"]), len(gt_density[0])-1)); y = max(0, min(int(p[\"y\"]), len(gt_density)-1))\n","      gt_density[y][x] = 1\n","    return gt_count, gt_density\n","\n","# Models pretrained on SHA or QNRF should perform best on dense crowds, SHB for sparse crowds.\n","#   Using SHAweights on relatively sparse crowds might also give very wrong results.\n","#   On the other hand, SHB might perform better as the weights were trained on Shanghai B data set, which containts images with relatively sparse crowds.\n","#   Using high quality images with sparse crowds might also yield bad results, as the algorithms might mistake some textures of clothings for a crowd.\n","WEIGHTS_FOR_MODELS = {\"CSRNet\": [\"SHA\", \"SHB\"], \"Bay\": [\"SHA\", \"SHB\", \"QNRF\"], \"DM-Count\": [\"SHA\", \"SHB\", \"QNRF\"], \"SFANet\": [\"SHB\"]}\n","\n","class ModelEvaluator(object):\n","  def __init__(self, dataset_name, model_name, model_weights):\n","    self.dataset_name = dataset_name\n","    if model_name not in [\"CSRNet\", \"Bay\", \"DM-Count\", \"SFANet\"]:\n","      raise ValueError(model_name)\n","    self.model_name = model_name\n","    if model_weights not in WEIGHTS_FOR_MODELS[model_name]:\n","      raise ValueError(model_weights)\n","    self.model_weights = model_weights\n","    self.model = LWCC.load_model(model_name=model_name, model_weights=model_weights)\n","    self.model_str = f\"{self.model_name}-{self.model_weights}\"\n","\n","  def evaluate(self, img_paths, gt_count, gt_density, vis = 0, is_gray = False):\n","    pred_count, pred_density = self._inference(img_paths, is_gray=is_gray)\n","    metrics = Metrics(self.model_str, gt_count, gt_density, pred_count, pred_density, img_paths)\n","    pred_vis = {self.model_str: {\n","        \"count\": pred_count[:vis], \"density\": pred_density[:vis],\n","        \"img_metrics\": [metrics.metrics_by_img[os.path.basename(p)] for p in img_paths[:vis]]\n","    }}\n","    return metrics, pred_vis\n","\n","  def _inference(self, image_paths, resize_image = True, return_density = True, is_gray = False):\n","    \"\"\" Returns two dictionaries: {img_name: count}, {img_name: density} \"\"\"\n","    pred_count = []; pred_density = []\n","    for img_path in tqdm(image_paths, desc=f\"{self.model_name} - {self.model_weights} on {self.dataset_name}\", disable=True):\n","      pred_c, pred_d = LWCC.get_count(\n","        img_path, resize_img=resize_image, return_density=return_density, model=self.model, is_gray = is_gray\n","      )\n","      pred_count.append(pred_c); pred_density.append(pred_d)\n","      # print(f'{os.path.basename(img_path).replace(\".jpg\", \"\")}, {pred_c}')\n","    if return_density:\n","      return pred_count, pred_density\n","    else:\n","      return pred_count\n","\n","class Evaluator(object):\n","  def evaluate(self, dataset, vis=0, eval_limit=0, batch=0, is_gray=False):\n","    img_paths = dataset.get_image_paths()\n","    if eval_limit:\n","      img_paths = img_paths[:eval_limit]\n","    if batch == 1:\n","      # Process the first half of the images\n","      img_paths = img_paths[:int(len(img_paths)/2)]\n","    elif batch == 2:\n","      # Process the final half of the images\n","      img_paths = img_paths[int(len(img_paths)/2):]\n","    if batch != 0:\n","      print(f\"Batch {batch}/2:\", [os.path.basename(i) for i in img_paths])\n","    # Else: Don't split into batches\n","    gt_count, gt_density = zip(*[dataset.get_gt_for_img(img_path) for img_path in img_paths])\n","\n","    metrics = {}\n","    preds_vis = [{} for _ in range(vis)]\n","    for model in WEIGHTS_FOR_MODELS:\n","      metrics[model] = {}\n","      for weights in WEIGHTS_FOR_MODELS[model]:\n","        # print()\n","        # print(model, weights)\n","        evaluator = ModelEvaluator(dataset.name, model, weights)\n","        metric, pred_vis = evaluator.evaluate(img_paths, gt_count, gt_density, vis=vis, is_gray=is_gray)\n","        metrics[model][weights] = metric\n","        for model_name, preds in pred_vis.items():\n","          for i in range(vis):\n","            preds_vis[i][model_name] = {\"count\": preds[\"count\"][i], \"density\": preds[\"density\"][i], \"img_metrics\": preds[\"img_metrics\"][i]}\n","    self.print_metrics(metrics, dataset)\n","    self.visualize_results(gt_count, gt_density, preds_vis, img_paths, metrics, dataset.name)\n","    return metrics\n","\n","  def visualize_results(self, gt_count, gt_density, predictions, img_paths, metrics, dataset_name):\n","    print()\n","    print(\"Visualization\")\n","    for gt_c, gt_d, preds, img_p in zip(gt_count, gt_density, predictions, img_paths):\n","      raw_image = cv2.cvtColor(cv2.imread(img_p), cv2.COLOR_BGR2RGB)\n","      plt.rcParams['axes.facecolor'] = 'white'\n","      fig = plt.figure(figsize=(18, 10))\n","      fig.add_subplot(3, 4, 1); plt.imshow(raw_image); plt.axis('off'); plt.title(r\"$\\bf{\" + f\"{dataset_name}:\"  + r\"}$ \" + f\"{os.path.basename(img_p)}\")\n","      fig.add_subplot(3, 4, 2); plt.imshow(gt_d); plt.axis('off'); plt.title(r\"$\\bf{\" + f\"Ground \\ Truth: {gt_c}\" + r\"}$\")\n","      for i, (model, pred) in enumerate(preds.items(), start=3):\n","        p_c, p_d, p_m = pred[\"count\"], pred[\"density\"], pred[\"img_metrics\"]\n","        fig.add_subplot(3, 4, i); plt.imshow(p_d); plt.axis('off');\n","        plt.title((r\"$\\bf{\" + f\"{model}: %.1f\" % p_c) + r\"}$\" + \"\\n\" + (\"MAE: %.1f, GAME16: %.1f\") % (p_m[\"MAE\"], p_m[\"GAME16\"]))\n","      plt.show()\n","      plt.close()\n","\n","  def print_metrics(self, metrics, dataset):\n","    print()\n","    print(f\"Metrics for {dataset.name}:\")\n","    print(\"Model, MAE, MSE, RMSE, GAME4, GAME16, PSNR, SSIM\")\n","    for model in metrics:\n","      for weights, metric in metrics[model].items():\n","        metric.display_metrics()\n","  \n","evaluator = Evaluator()\n","metrics = {}"]},{"cell_type":"markdown","metadata":{"id":"m_l-14x8M6Lu"},"source":["## Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QJcyEGskM7Rj"},"outputs":[],"source":["evaluator.evaluate(ShanghaiTech(\"A\"), vis=1, eval_limit=1)"]},{"cell_type":"markdown","metadata":{"id":"94mSzOL0M7WC"},"source":["## Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bcFa7pb_M91B"},"outputs":[],"source":["metrics[\"MT\"] = evaluator.evaluate(MT(), vis=56)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AA9C5_tZM93m"},"outputs":[],"source":["metrics[\"SHA\"] = evaluator.evaluate(ShanghaiTech(\"A\"), vis=60)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ZRin1DkM9_z"},"outputs":[],"source":["metrics[\"SHB\"] = evaluator.evaluate(ShanghaiTech(\"B\"), vis=60, batch=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUJRbMw1sswF"},"outputs":[],"source":["metrics[\"SHB2\"] = evaluator.evaluate(ShanghaiTech(\"B\"), vis=60, batch=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-K99XAnDM-T_"},"outputs":[],"source":["metrics[\"UCFCC50\"] = evaluator.evaluate(UCF(\"CC50\"), vis=50, is_gray=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eT4TfacnM-YA"},"outputs":[],"source":["metrics[\"UCF-QNRF\"] = evaluator.evaluate(UCF(\"QNRF\"), vis=60, batch=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dWu-g9IaZUQW"},"outputs":[],"source":["metrics[\"UCF-QNRF_2\"] = evaluator.evaluate(UCF(\"QNRF\"), vis=60, batch=2)"]},{"cell_type":"markdown","metadata":{"id":"4QmtmmU5DFGq"},"source":["# SASNet\n","\n","https://github.com/TencentYoutuResearch/CrowdCounting-SASNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYjbXiW7DFRq"},"outputs":[],"source":["import sys\n","import torch\n","\n","from torchvision import transforms\n","\n","SASNET_PATH = f\"{MODELS_PATH}/SASNet\"\n","SASNET_WEIGHTS = f\"{SASNET_PATH}/checkpoints\"\n","sys.path.append(os.path.abspath(SASNET_PATH))\n","from model import SASNet\n","from lwcc.util.functions import load_image\n","\n","DEVICE = 'cpu'\n","DEVICE = 'cuda'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9L2Ho2FRDGfO"},"outputs":[],"source":["class SASNetModelEvaluator(ModelEvaluator):\n","  def __init__(self, dataset_name, model_weights):\n","    self.dataset_name = dataset_name\n","    self.model_name = \"SASNet\"\n","    if model_weights not in [\"SHHA\", \"SHHB\"]:\n","      raise ValueError(model_weights)\n","    self.model_weights = model_weights\n","    self.log_para = 1000 # Post-processing: Model magnify the target density map, must be reduced\n","    self.model = SASNet()\n","    device = torch.device(DEVICE)\n","    self.model.to(device)\n","    self.model = self.model.cuda()\n","    self.model.load_state_dict(torch.load(f\"{SASNET_WEIGHTS}/{model_weights}.pth\", map_location=device))\n","    self.model.eval() # Evaluation mode https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch\n","    self.model_str = f'{self.model_name}-{(\"SHA\" if model_weights == \"SHHA\" else \"SHB\")}'\n","\n","  def _inference(self, image_paths, is_gray=False):\n","    pred_count = []; pred_density = []\n","    with torch.no_grad():\n","      for img_path in tqdm(image_paths, desc=f\"{self.model_str} on {self.dataset_name}\", disable=False):\n","        # LWCC Load image. Applies transform https://github.com/tersekmatija/lwcc/blob/3675ce7a197eea992d522ee2320e1503439e5d19/lwcc/util/functions.py#L44\n","        #   Same as SASNet and other CC loaders\n","        img, name = load_image(img_path, self.model_name, is_gray=is_gray)\n","        img = torch.Tensor(img)\n","        img = img.to(DEVICE)\n","        result = self.model(img).cpu()\n","        pred_d = result[0, 0, :, :].numpy()\n","        pred_d = pred_d/self.log_para # Model magnifies target density map, it must be reduced\n","        pred_c = np.sum(pred_d)\n","        pred_count.append(pred_c); pred_density.append(pred_d)\n","        # print(f'{os.path.basename(img_path).replace(\".jpg\", \"\")}, {pred_c}')\n","      return pred_count, pred_density\n","\n","class SASNetEvaluator(Evaluator):\n","  def evaluate(self, dataset, vis=0, eval_limit=0, batch=0, is_gray=False):\n","    img_paths = dataset.get_image_paths()\n","    if eval_limit:\n","      img_paths = img_paths[:eval_limit]\n","    if batch == 1:\n","      # Process the first half of the images\n","      img_paths = img_paths[:int(len(img_paths)/2)]\n","    elif batch == 2:\n","      # Process the final half of the images\n","      img_paths = img_paths[int(len(img_paths)/2):]\n","    if batch != 0:\n","      print(f\"Batch {batch}/2:\", [os.path.basename(i) for i in img_paths])\n","    # Else: Don't split into batches\n","    gt_count, gt_density = zip(*[dataset.get_gt_for_img(img_path) for img_path in img_paths])\n","\n","    metrics = {\"SASNet\": {}}\n","    preds_vis = [{} for _ in range(vis)]\n","    for weights in [\"SHHA\", \"SHHB\"]:\n","      # print()\n","      # print(\"SASNet\", weights)\n","      evaluator = SASNetModelEvaluator(dataset.name, weights)\n","      metric, pred_vis = evaluator.evaluate(img_paths, gt_count, gt_density, vis=vis, is_gray=is_gray)\n","      metrics[\"SASNet\"][weights] = metric\n","      for model_name, preds in pred_vis.items():\n","        for i in range(vis):\n","          preds_vis[i][model_name] = {\"count\": preds[\"count\"][i], \"density\": preds[\"density\"][i], \"img_metrics\": preds[\"img_metrics\"][i]}\n","    self.print_metrics(metrics, dataset)\n","    self.visualize_results(gt_count, gt_density, preds_vis, img_paths, metrics, dataset.name)\n","    return metrics\n","\n","sasnet_evaluator = SASNetEvaluator();\n","metrics = {}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZAP34iEuDHmh"},"outputs":[],"source":["sasnet_evaluator.evaluate(ShanghaiTech(\"A\"), vis=1, eval_limit=1);"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"H_9mKepqDI3J"},"outputs":[],"source":["metrics[\"MT\"] = sasnet_evaluator.evaluate(MT(), vis=56)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5UJImGynwR1Q"},"outputs":[],"source":["metrics[\"SAS-SHA\"] = sasnet_evaluator.evaluate(ShanghaiTech(\"A\"), vis=60)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AYzA4kU1wR9R"},"outputs":[],"source":["metrics[\"SAS-SHB\"] = sasnet_evaluator.evaluate(ShanghaiTech(\"B\"), vis=60, batch=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J1QFZ7dswSAE"},"outputs":[],"source":["metrics[\"SAS-SHB2\"] = sasnet_evaluator.evaluate(ShanghaiTech(\"B\"), vis=60, batch=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gQHaAYPQwugG"},"outputs":[],"source":["metrics[\"SAS-UCFCC50\"] = sasnet_evaluator.evaluate(UCF(\"CC50\"), vis=50, is_gray=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2YwGwqanwums"},"outputs":[],"source":["metrics[\"SAS-UCF-QNRF\"] = sasnet_evaluator.evaluate(UCF(\"QNRF\"), vis=60, batch=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zq2WyJTewu3v"},"outputs":[],"source":["metrics[\"SAS-UCF-QNRF_2\"] = sasnet_evaluator.evaluate(UCF(\"QNRF\"), vis=60, batch=2)"]},{"cell_type":"markdown","metadata":{"id":"YWx_b25zJFBH"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zDLGcw9XJFNT"},"outputs":[],"source":["metrics[\"MT\"][\"SASNet\"][\"SHHB\"].metrics_by_img"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"13DpoToEIDMbiCaEVqSR50nmbqU6-X8AC","authorship_tag":"ABX9TyP27+JBowhvJNWa48wX5xfJ"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}